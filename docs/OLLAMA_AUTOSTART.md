# Ollama Auto-Start Functionality

## Vis√£o Geral

O sistema de trading multi-agente agora possui capacidade **autom√°tica de inicializa√ß√£o do Ollama** quando necess√°rio. Esta funcionalidade garante que a IA local esteja sempre dispon√≠vel para opera√ß√µes cr√≠ticas.

## Funcionalidades Implementadas

### ‚úÖ Auto-Start Integrado

**Componentes com Auto-Start:**
- **AI Agent** (`src/agents/ai_agent.py`)
- **Sentiment Analyzer** (`src/utils/gemma3_sentiment_analyzer.py`)

### ‚úÖ M√©todos de Inicializa√ß√£o

**1. SystemD Service (Preferencial)**
```bash
systemctl start ollama
```

**2. Processo Direto (Fallback)**
```bash
ollama serve &
```

### ‚úÖ Detec√ß√£o Inteligente

O sistema detecta automaticamente:
- ‚úÖ Disponibilidade do `systemctl`
- ‚úÖ Exist√™ncia do servi√ßo `ollama.service`
- ‚úÖ Localiza√ß√£o do bin√°rio `ollama`
- ‚úÖ Status de conectividade (porto 11434)

## Como Funciona

### Fluxo de Auto-Start

1. **Health Check Falha** ‚Üí Detec√ß√£o de Ollama offline
2. **Tentativa SystemD** ‚Üí `systemctl start ollama`
3. **Fallback Direto** ‚Üí `ollama serve` em background
4. **Aguardo** ‚Üí 3 segundos para inicializa√ß√£o
5. **Verifica√ß√£o** ‚Üí Novo health check
6. **Recupera√ß√£o** ‚Üí Sistema continua opera√ß√£o normal

### Implementa√ß√£o T√©cnica

**AI Agent (Async):**
```python
async def _try_start_ollama(self) -> bool:
    # Tentativa via systemctl
    if shutil.which("systemctl"):
        process = await asyncio.create_subprocess_exec(
            "systemctl", "start", "ollama"
        )
        if process.returncode == 0:
            return True
    
    # Fallback direto
    await asyncio.create_subprocess_exec("ollama", "serve")
    return True
```

**Sentiment Analyzer (Sync):**
```python
def _try_start_ollama(self) -> bool:
    # Tentativa via systemctl
    if shutil.which("systemctl"):
        result = subprocess.run(["systemctl", "start", "ollama"])
        if result.returncode == 0:
            return True
    
    # Fallback direto
    subprocess.Popen(["ollama", "serve"])
    return True
```

## Teste da Funcionalidade

### Script de Teste Autom√°tico

```bash
python test_ollama_autostart.py
```

**Resultados dos Testes:**
```
üéâ All tests passed! Ollama auto-start is working correctly.

AI Agent Auto-Start: ‚úÖ PASS
Sentiment Analyzer Auto-Start: ‚úÖ PASS
```

### Teste Manual

1. **Parar Ollama:**
   ```bash
   sudo systemctl stop ollama
   ```

2. **Executar Bot:**
   ```bash
   cd src && python multi_agent_bot.py
   ```

3. **Verificar Logs:**
   ```
   INFO - Attempting to start Ollama via systemctl...
   INFO - Successfully started Ollama service via systemctl
   INFO - Local AI is available and responding
   ```

## Configura√ß√£o do Sistema

### Pr√©-Requisitos

**‚úÖ Seu Sistema (Verificado):**
- Ubuntu/Linux com systemd
- Ollama instalado em `/usr/local/bin/ollama`
- Servi√ßo configurado: `/etc/systemd/system/ollama.service`
- Servi√ßo habilitado: `enabled`

### Configura√ß√£o Opcional

**Timeout Personalizado:**
```yaml
ai_agent:
  model_settings:
    timeout_seconds: 30  # Tempo para auto-start
```

**Desabilitar Auto-Start (se necess√°rio):**
```python
# Em development apenas
AUTO_START_ENABLED = False
```

## Vantagens

### üöÄ **Opera√ß√£o Sem Interrup√ß√£o**
- Sistema continua funcionando mesmo se Ollama parar
- Recupera√ß√£o autom√°tica de falhas
- Zero downtime para trading

### üîÑ **Recupera√ß√£o Robusta**
- M√∫ltiplas estrat√©gias de inicializa√ß√£o
- Fallbacks inteligentes
- Detec√ß√£o de ambiente autom√°tica

### üìä **Monitoramento Integrado**
- Logs detalhados de auto-start
- Health checks cont√≠nuos
- Alertas de falha configur√°veis

## Logs de Exemplo

### Sucesso SystemD
```
2025-06-13 02:11:38 - ai_agent - INFO - Attempting to start Ollama via systemctl...
2025-06-13 02:11:43 - ai_agent - INFO - Successfully started Ollama service via systemctl
```

### Fallback Direto
```
2025-06-13 02:12:10 - grid_bot - WARNING - Ollama service not available
2025-06-13 02:12:10 - grid_bot - INFO - Attempting to start Ollama directly...
2025-06-13 02:12:13 - grid_bot - INFO - Started Ollama serve in background
```

## Seguran√ßa

### ‚úÖ **Valida√ß√µes Implementadas**
- Verifica√ß√£o de bin√°rios antes da execu√ß√£o
- Timeout em tentativas de start (10s)
- Preven√ß√£o de recurs√£o infinita
- Logs de auditoria completos

### ‚ö†Ô∏è **Considera√ß√µes**
- Requer permiss√µes para `systemctl start`
- Usuario deve estar no grupo adequado
- Processo direto roda com permiss√µes do usu√°rio

## Manuten√ß√£o

### Verifica√ß√£o de Status
```bash
systemctl status ollama
ps aux | grep ollama
curl -s http://localhost:11434/api/tags
```

### Logs do Sistema
```bash
tail -f /var/log/syslog | grep ollama
journalctl -u ollama -f
```

### Troubleshooting

**Problema: Auto-start falha**
```bash
# Verificar permiss√µes
sudo systemctl start ollama

# Verificar instala√ß√£o
which ollama
ollama --version
```

**Problema: Timeout**
```bash
# Aumentar timeout na configura√ß√£o
model_settings:
  timeout_seconds: 60
```

## Status Atual

‚úÖ **Implementado e Testado**
- Auto-start via SystemD ‚úÖ
- Auto-start via processo direto ‚úÖ  
- Integra√ß√£o AI Agent ‚úÖ
- Integra√ß√£o Sentiment Analyzer ‚úÖ
- Testes automatizados ‚úÖ
- Documenta√ß√£o completa ‚úÖ

**Resultado:** Sistema de trading completamente aut√¥nomo com IA local auto-recuper√°vel!